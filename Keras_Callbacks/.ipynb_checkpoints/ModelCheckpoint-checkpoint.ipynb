{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoint to Save Weights\n",
    "You've now trained a neural network or two, but how can we actually make use of the \"magic\" of the model?  If the problem we're trying to solve is classifying a breast cancer tumor as benign or malignant, what do we do after we get the pretty >$98\\%$ accuracy?  The answer is to save the weights and model into a separate file to access later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up data\n",
    "data = np.array(pd.read_table(\n",
    "    \"https://www.cs.mtsu.edu/~jphillips/courses/CSCI4850-5850/public/WDBC.txt\",\n",
    "    delim_whitespace=True,\n",
    "    header=None))\n",
    "\n",
    "# Separate data into features and labels\n",
    "nb_features = 30\n",
    "X = data[:, :nb_features]\n",
    "Y = data[:, nb_features]\n",
    "X, Y = shuffle(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the purposes of this example, we will skip splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               3968      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,609\n",
      "Trainable params: 20,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a simple neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X.shape[1],), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizer=Adam(lr=1e-2), \n",
    "            metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, everything has been the same as we have done.  The only change to make is to add a callback, and then pass the callback to the fit() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory to hold the weights\n",
    "weight_dir = \"weights\"\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "\n",
    "# the filename will be populated at the end of each epoch, when the callback is called\n",
    "# values enclosed in curly braces will be substitued by Keras\n",
    "weight_filename = \"wdbc-weights_epoch-{epoch:04d}_acc-{acc:.2f}.hdf5\"\n",
    "weight_filepath = os.path.join(weight_dir, weight_filename)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_filepath, \n",
    "                         monitor='acc', \n",
    "                         verbose=0,)\n",
    "\n",
    "# the argument passed into the fit() function must be a list\n",
    "# if using multiple callbacks, you can use the .append() function or initialize them inline\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more arguments which can be passed to ModelCheckpoint(), and you can see them here: https://keras.io/callbacks/#modelcheckpoint\n",
    "\n",
    "The key parameters in practice are the name of the file itself, and whether or not to save only the weights or the weights alongside the model architecture.  This allows you to keep track of all the models you make and access them easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "568/568 [==============================] - 0s 306us/step - loss: 0.5394 - acc: 0.7570\n",
      "Epoch 2/10\n",
      "568/568 [==============================] - 0s 60us/step - loss: 0.2803 - acc: 0.8908\n",
      "Epoch 3/10\n",
      "568/568 [==============================] - 0s 71us/step - loss: 0.1934 - acc: 0.9173\n",
      "Epoch 4/10\n",
      "568/568 [==============================] - 0s 55us/step - loss: 0.1656 - acc: 0.9296\n",
      "Epoch 5/10\n",
      "568/568 [==============================] - 0s 65us/step - loss: 0.1487 - acc: 0.9331\n",
      "Epoch 6/10\n",
      "568/568 [==============================] - 0s 74us/step - loss: 0.1237 - acc: 0.9454\n",
      "Epoch 7/10\n",
      "568/568 [==============================] - 0s 69us/step - loss: 0.1216 - acc: 0.9454\n",
      "Epoch 8/10\n",
      "568/568 [==============================] - 0s 60us/step - loss: 0.1214 - acc: 0.9489\n",
      "Epoch 9/10\n",
      "568/568 [==============================] - 0s 76us/step - loss: 0.1147 - acc: 0.9525\n",
      "Epoch 10/10\n",
      "568/568 [==============================] - 0s 67us/step - loss: 0.0914 - acc: 0.9683\n"
     ]
    }
   ],
   "source": [
    "history_xor = model.fit(X, Y,\n",
    "                       batch_size=64,\n",
    "                       epochs=10,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check and see what's inside our weights folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wdbc-weights_epoch-0001_acc-0.76.hdf5',\n",
       " 'wdbc-weights_epoch-0002_acc-0.89.hdf5',\n",
       " 'wdbc-weights_epoch-0003_acc-0.92.hdf5',\n",
       " 'wdbc-weights_epoch-0004_acc-0.93.hdf5',\n",
       " 'wdbc-weights_epoch-0005_acc-0.93.hdf5',\n",
       " 'wdbc-weights_epoch-0006_acc-0.95.hdf5',\n",
       " 'wdbc-weights_epoch-0007_acc-0.95.hdf5',\n",
       " 'wdbc-weights_epoch-0008_acc-0.95.hdf5',\n",
       " 'wdbc-weights_epoch-0009_acc-0.95.hdf5',\n",
       " 'wdbc-weights_epoch-0010_acc-0.97.hdf5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_files = os.listdir(weight_dir)\n",
    "weight_files.sort()\n",
    "weight_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have access to all of our weights! We can load a model up and test it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               3968      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,609\n",
      "Trainable params: 20,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the most recent file (last element in the sorted list)\n",
    "weight_file_to_load = os.path.join(weight_dir, weight_files[-1])\n",
    "model_2 = load_model(weight_file_to_load)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 0s 159us/step\n",
      "Loaded model's evaluation: 97.18\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded model's evaluation: {:.2f}\".format(100 * model_2.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These model files can be loaded up by any script running Keras to start making use of your classifications right away."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

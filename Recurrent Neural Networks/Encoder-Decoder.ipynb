{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Sequence-to-Sequence Mappings\n",
    "\n",
    "Many times, we want to map an arbitrary length sequence to another arbitrary length sequence for a machine learning task. The most common example would be for machine translation where the number of characters/words used to encode a sentence in one language rarely matches with the number of characters/works used to encode a sentence with the same meaning in another language. Thus, the many-to-many mapping used by the simple recurrent network used in the previous example will not be approprite.\n",
    "\n",
    "In order to accomplish this task, the most common architecture used at this time is the *encoder-decoder* framework. First, we build an *encoder* network which takes an arbitrary length input sequence, and encodes a distributed representation of that input sequence using the hidden layer of a recurrent network. This is similar to a standard many-to-many recurrent network, except there is no output layer for the encoder. Instead, the input sequence information is simply folded into the hidden layer activation pattern at each time step. Once the encoder finishes generating a *gestalt* representation of the input sequence (using a recurrent hidden layer), the hidden layer activations are fed into a *decoder* network which translates the *gestalt* representation into the corresponding output sequence using another recurrent hidden layer and time-distributed output layer. Special *start* and *stop* patterns are used to encode for the starting and ending points of target sequences during training, so the *decoder* network learns to indicate when it is ready to start and finish a particular output sequence. Using its two subnetworks, the encoder-decoder framework forms a general sequence-to-sequence learning framework.\n",
    "\n",
    "In order to illustrate how to build and train an encoder-decoder network, we will utilize the parity task from the simple recurrent network example. Even though the sequence lengths are the same for both the input and output for this task, we can still utilize it to illustrate the core concepts involved. Also, we will be using long short-term memory for the recurrent layers of these networks to show their effectiveness at learning these kinds of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import what we need for the job...\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the parity problem again, but we need to encode the input and target sequences a bit more generically this time to show how the process might be generalized to other types of sequence processing domains.\n",
    "\n",
    "One key idea is that we need to map our possible sequence elements into a one-hot encoding dictionary which will be useful for arbitray sequence specification for both the encoder and decoder parts of the network. We will use the following mapping:\n",
    "\n",
    "Input Sequences:\n",
    "\n",
    "| Symbol | One-hot Encoding |\n",
    "| --- | --- |\n",
    "| `0` | `10` |\n",
    "| `1` | `01` |\n",
    "\n",
    "Ouput Sequences:\n",
    "\n",
    "| Symbol | One-hot Encoding |\n",
    "| --- | --- |\n",
    "| `0` | `1000` |\n",
    "| `1` | `0100` |\n",
    "| start | `0010` |\n",
    "| stop  | `0001` |\n",
    "\n",
    "This encoding will necessarily make the problem easier to solve (0 is now mapped to a meaningful orthogonal dimension to the other symbols), but more importantly, it shows how each symbol in the input/output sequences needs an orthogonal dimension in the encoded form. Other distributed codes may also work, but high dot product similarity between vectors in the encoding chosen may affect the network's learning capabilities in unpredictable ways (more than likely negative). Also, it should be clear here that we don't even need to have the same *symbols* in the encoder and decoder networks. They can be arbitrary mappings in both time and space, which makes this a powerful, flexible approach.\n",
    "\n",
    "OK, so let's generate a large set of training and testing sequences for the network to experience on this task..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of sequences to model\n",
    "length = 10\n",
    "\n",
    "# Note we are making these the same, but they don't -have- to be!\n",
    "input_length = length\n",
    "output_length = length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a good rule of thumb, we just want to create a network and train it to learn just a single example first. After that, we can extend it to a larger data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a random string of 0s and 1s\n",
    "x_train = np.round(np.random.uniform(0,1,[length])).reshape([1,length,1])\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate parity (note this is the same algorithmic approach\n",
    "# that we are trying to encourage our net to learn!)\n",
    "def parity(x):\n",
    "    temp = np.zeros(x.shape)\n",
    "    mem = False\n",
    "    # Iterate over the sequence\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i,0] > 0.5:\n",
    "            current = True\n",
    "        else:\n",
    "            current= False\n",
    "        mem = np.logical_xor(mem,current)\n",
    "        if mem:\n",
    "            temp[i,0] = 1.0\n",
    "        else:\n",
    "            temp[i,0] = 0.0\n",
    "    return (temp.reshape(1,temp.shape[0],temp.shape[1])) # Tensor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = parity(x_train[0,:,:])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn these into a set of encoded input-output vectors using the transformation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.expand_dims(keras.utils.to_categorical(x_train[0,:,0]),axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.expand_dims(np.vstack([np.array([0,0,1,0]),\n",
    "                   np.hstack([keras.utils.to_categorical(y_train[0,:,0]),np.zeros([input_length,2])]),\n",
    "                   np.array([0,0,0,1])]),axis=0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, note the shapes of the sequences..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to divide the target data into two groups which correspond to the input-target pairs for the *decoder* network. In essence, the decoder network is really just a many-to-many recurrent network, and will be trying to predict the next part of the target sequence (`postY`) given *both* the encoder output representation *and* the previous target sequence entry (`preY`). This previous target sequence entry is not strictly necessary, but using it represents a training strategy called *teacher forcing* which makes it easier to learn some sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 time steps total (10 + start + stop)\n",
    "# Divide into two groups of 11\n",
    "# First from 0 ... 10\n",
    "preY = Y[:,1:output_length+2,:]\n",
    "# Second from 1 ... 11\n",
    "postY = Y[:,0:output_length+1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's make an encoder-decoder framework for learning this sequence. We need to use the Keras *functional* API for building this network as well. To create networks of this kind, we first create `layer` objects and then call their `()` functions to make them take inputs from the provided layers' outputs. This allows for networks to receieve input from more than one layer at a time, or pass their outputs to more than one layer at a time. Once all of the layers have been connected in the desired ways, then we create a `Model` object which is provided a set of input and output layers for the overall model. This allows for more general network topologies to be constructed than can be achieved with the *sequential* API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 20), (None,  1840        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, None, 20), ( 2000        input_12[0][0]                   \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "==================================================================================================\n",
      "Total params: 3,840\n",
      "Trainable params: 3,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Size of the gestalt, context representations...\n",
    "encoder_hidden_size = input_length*2\n",
    "decoder_hidden_size = output_length*2\n",
    "\n",
    "## Encoder Construction\n",
    "\n",
    "# Make the layers\n",
    "encoder_input = keras.layers.Input(shape=(None, X.shape[2]))\n",
    "encoder_hidden = keras.layers.LSTM(encoder_hidden_size, return_state=True)\n",
    "# Tie the hidden layer to the input layer (passed in) \n",
    "encoder_output, enc_state_h, enc_state_c = encoder_hidden(encoder_input)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [enc_state_h, enc_state_c]\n",
    "\n",
    "## Decoder Construction\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_input = keras.layers.Input(shape=(None, Y.shape[2]))\n",
    "decoder_hidden = keras.layers.LSTM(decoder_hidden_size, return_sequences=True, return_state=True)\n",
    "# Connect hidden to input (also reads from the encoder...)\n",
    "decoder_output, dec_state_h, dec_state_c = decoder_hidden(decoder_input,\n",
    "                                                          initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(Y.shape[2], activation='softmax')\n",
    "# Connect output to hidden\n",
    "decoder_outputs = decoder_dense(decoder_output)\n",
    "\n",
    "# Our functional API model now has -two- input layers:\n",
    "# 1. Reads from X\n",
    "# 2. Reads from preY\n",
    "# and has a -single- output layer...\n",
    "# 1. Targets are postYY\n",
    "model = keras.Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "# Compile it...\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 277.00 191.00\" width=\"277pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 273,-187 273,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140461161087496 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140461161087496</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 132,-182.5 132,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-160.8\">input_11: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140461161089176 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140461161089176</title>\n",
       "<polygon fill=\"none\" points=\"13.5,-73.5 13.5,-109.5 118.5,-109.5 118.5,-73.5 13.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-87.8\">lstm_10: LSTM</text>\n",
       "</g>\n",
       "<!-- 140461161087496&#45;&gt;140461161089176 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140461161087496-&gt;140461161089176</title>\n",
       "<path d=\"M66,-146.313C66,-138.289 66,-128.547 66,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"69.5001,-119.529 66,-109.529 62.5001,-119.529 69.5001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140461161087832 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140461161087832</title>\n",
       "<polygon fill=\"none\" points=\"137,-73.5 137,-109.5 269,-109.5 269,-73.5 137,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203\" y=\"-87.8\">input_12: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140461159115856 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140461159115856</title>\n",
       "<polygon fill=\"none\" points=\"81.5,-0.5 81.5,-36.5 186.5,-36.5 186.5,-0.5 81.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134\" y=\"-14.8\">lstm_11: LSTM</text>\n",
       "</g>\n",
       "<!-- 140461161087832&#45;&gt;140461159115856 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140461161087832-&gt;140461159115856</title>\n",
       "<path d=\"M186.297,-73.3129C177.737,-64.5046 167.164,-53.625 157.769,-43.9584\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"160.029,-41.2609 150.549,-36.5288 155.009,-46.1395 160.029,-41.2609\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140461161089176&#45;&gt;140461159115856 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140461161089176-&gt;140461159115856</title>\n",
       "<path d=\"M82.4609,-73.3129C90.897,-64.5046 101.317,-53.625 110.575,-43.9584\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.302,-46.1718 117.691,-36.5288 108.246,-41.33 113.302,-46.1718\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization - wish we could see the recurrent weights!\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
